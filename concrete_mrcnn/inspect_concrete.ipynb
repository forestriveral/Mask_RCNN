{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import concrete_tools\n",
    "from concrete import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...To clean logs in /home/forestriveral/DeepLearning/Keras/Mask_RCNN/logs\n",
      "==> Empty logs dir clean done in /home/forestriveral/DeepLearning/Keras/Mask_RCNN/logs\n",
      "Command Executed:  train\n",
      "Weights:  coco\n",
      "Dataset:  /home/forestriveral/DeepLearning/Keras/Mask_RCNN/datasets\n",
      "Logs:  /home/forestriveral/DeepLearning/Keras/Mask_RCNN/logs\n",
      "==> Train mode: Network heads\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           concrete\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                50\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  /home/forestriveral/DeepLearning/Keras/Mask_RCNN/mask_rcnn_coco.h5\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/forestriveral/DeepLearning/Keras/Mask_RCNN/logs/concrete20181128T2034/mask_rcnn_concrete_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 2.4397 - rpn_class_loss: 0.0466 - rpn_bbox_loss: 1.6198 - mrcnn_class_loss: 0.1967 - mrcnn_bbox_loss: 0.3596 - mrcnn_mask_loss: 0.2168 - val_loss: 5.1267 - val_rpn_class_loss: 0.0967 - val_rpn_bbox_loss: 1.9247 - val_mrcnn_class_loss: 1.0539 - val_mrcnn_bbox_loss: 1.4062 - val_mrcnn_mask_loss: 0.6452\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 12s 231ms/step - loss: 2.0974 - rpn_class_loss: 0.0343 - rpn_bbox_loss: 0.9763 - mrcnn_class_loss: 0.1109 - mrcnn_bbox_loss: 0.4931 - mrcnn_mask_loss: 0.4828 - val_loss: 2.9023 - val_rpn_class_loss: 0.0444 - val_rpn_bbox_loss: 1.0446 - val_mrcnn_class_loss: 0.4190 - val_mrcnn_bbox_loss: 0.9421 - val_mrcnn_mask_loss: 0.4522\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 11s 229ms/step - loss: 1.8404 - rpn_class_loss: 0.0313 - rpn_bbox_loss: 0.9668 - mrcnn_class_loss: 0.0956 - mrcnn_bbox_loss: 0.4163 - mrcnn_mask_loss: 0.3303 - val_loss: 2.4929 - val_rpn_class_loss: 0.0302 - val_rpn_bbox_loss: 0.7936 - val_mrcnn_class_loss: 0.4333 - val_mrcnn_bbox_loss: 0.7199 - val_mrcnn_mask_loss: 0.5159\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 1.4457 - rpn_class_loss: 0.0238 - rpn_bbox_loss: 0.7211 - mrcnn_class_loss: 0.0515 - mrcnn_bbox_loss: 0.2939 - mrcnn_mask_loss: 0.3554 - val_loss: 2.2314 - val_rpn_class_loss: 0.0403 - val_rpn_bbox_loss: 0.8742 - val_mrcnn_class_loss: 0.1820 - val_mrcnn_bbox_loss: 0.8348 - val_mrcnn_mask_loss: 0.3001\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 13s 259ms/step - loss: 1.3121 - rpn_class_loss: 0.0221 - rpn_bbox_loss: 0.5711 - mrcnn_class_loss: 0.0918 - mrcnn_bbox_loss: 0.3189 - mrcnn_mask_loss: 0.3082 - val_loss: 1.9964 - val_rpn_class_loss: 0.0287 - val_rpn_bbox_loss: 0.8471 - val_mrcnn_class_loss: 0.1526 - val_mrcnn_bbox_loss: 0.6413 - val_mrcnn_mask_loss: 0.3267\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 1.4714 - rpn_class_loss: 0.0175 - rpn_bbox_loss: 0.8125 - mrcnn_class_loss: 0.0758 - mrcnn_bbox_loss: 0.2969 - mrcnn_mask_loss: 0.2686 - val_loss: 2.1015 - val_rpn_class_loss: 0.0187 - val_rpn_bbox_loss: 1.1085 - val_mrcnn_class_loss: 0.1017 - val_mrcnn_bbox_loss: 0.5931 - val_mrcnn_mask_loss: 0.2794\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 2.0200 - rpn_class_loss: 0.0194 - rpn_bbox_loss: 1.4082 - mrcnn_class_loss: 0.0615 - mrcnn_bbox_loss: 0.2927 - mrcnn_mask_loss: 0.2382 - val_loss: 2.6093 - val_rpn_class_loss: 0.0193 - val_rpn_bbox_loss: 1.3732 - val_mrcnn_class_loss: 0.1613 - val_mrcnn_bbox_loss: 0.6937 - val_mrcnn_mask_loss: 0.3618\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 13s 263ms/step - loss: 1.2558 - rpn_class_loss: 0.0126 - rpn_bbox_loss: 0.7865 - mrcnn_class_loss: 0.0437 - mrcnn_bbox_loss: 0.2212 - mrcnn_mask_loss: 0.1918 - val_loss: 2.0424 - val_rpn_class_loss: 0.0196 - val_rpn_bbox_loss: 1.1030 - val_mrcnn_class_loss: 0.1171 - val_mrcnn_bbox_loss: 0.5086 - val_mrcnn_mask_loss: 0.2941\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 1.6485 - rpn_class_loss: 0.0235 - rpn_bbox_loss: 1.0600 - mrcnn_class_loss: 0.0996 - mrcnn_bbox_loss: 0.2447 - mrcnn_mask_loss: 0.2206 - val_loss: 1.3890 - val_rpn_class_loss: 0.0104 - val_rpn_bbox_loss: 0.7904 - val_mrcnn_class_loss: 0.0733 - val_mrcnn_bbox_loss: 0.2508 - val_mrcnn_mask_loss: 0.2642\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 1.6912 - rpn_class_loss: 0.0235 - rpn_bbox_loss: 1.0434 - mrcnn_class_loss: 0.1097 - mrcnn_bbox_loss: 0.2429 - mrcnn_mask_loss: 0.2716 - val_loss: 1.9522 - val_rpn_class_loss: 0.0081 - val_rpn_bbox_loss: 0.6283 - val_mrcnn_class_loss: 0.0402 - val_mrcnn_bbox_loss: 1.0863 - val_mrcnn_mask_loss: 0.1892\n",
      "========training...\n",
      "\n",
      "...To clean logs in /home/forestriveral/DeepLearning/Keras/Mask_RCNN/logs\n",
      "==> Empty logs dir clean done in /home/forestriveral/DeepLearning/Keras/Mask_RCNN/logs\n"
     ]
    }
   ],
   "source": [
    "stage = [1, 0, 0]\n",
    "epochs = [10, 40, 80]\n",
    "\n",
    "concrete_tools.concrete_train_schedule(epochs, version='000', stage=stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
